# Zusammenfassung der gesamten Arbeit

Zu Beginn des Projekts wurden zunächst verschiedene Libraries und APIs hinsichtlich ihrer Vor- und Nachteile untersucht. Hierbei hat sich die [Alpha Vantage API](../python_files/alphavantage.py) als die vorteilhafteste Lösung erwiesen, da sie eine Vielzahl an Daten bereitstellt und kostenlos zur Verfügung steht. Mit dem API-Request "Company Overview" wurden die wichtigsten Aktienkennzahlen ausgegeben. Das Ergebnis dieser Anfrage ist ein JSON-Objekt, das sich für spätere Zwecke speichern und manipulieren lässt. Ferner wurde ein Algorithmus entwickelt, der es ermöglicht, den Request für jeden Ticker anzuwenden. Schließlich wurden die gesamten Ergebnisse in einer [CSV-Datei](../data/stocks_data.csv) gespeichert, um eine einfache Verarbeitung und Analyse zu ermöglichen.

Ein weiterer wichtiger Bestandteil des Projekts war die Entwicklung eines [Web Scrapers](../notebooks/web_scraper.ipynb). Dieser sollte es ermöglichen, tagesaktuelle Nachrichten zu bestimmten Unternehmen und deren Branche zu extrahieren, um schnell und informiert Investitionsentscheidungen treffen oder revidieren zu können. Um dies zu erreichen, wurden verschiedene Nachrichten- und Finanzseiten untersucht, die übersichtlich die entsprechenden Unternehmensmeldungen zu jeder Branche darstellen. Hierbei wäre Bloomberg die beste Wahl gewesen, jedoch sind die Artikel auf dieser Seite hinter einer Paywall verborgen. Aus diesem Grund wurde die Alternativ [finanzen.net](https://finanzen.net) gewählt. Auf dieser werden die wichtigsten Meldungen in Form von News Cards dargestellt. Diese bestehen zum einem aus einer Überschrift, die zugleich auch der Hyperlink zu dem Artikel ist und einem Teaser. Ziel war es hierbei, alle Hyperlinks zu extrahieren und um später auf die Artikel zugreifen zu können. Für die Durchführung des Web Scrapings wurde die Bibliothek Beautiful Soup verwendet, die es ermöglicht, die einzelnen HTML-Tags eines Dokuments anzusteuern. Durch die Verwendung dieser Bibliothek war es einfach, auf die wesentlichen Inhalte eines Artikels zuzugreifen, die sich in den Überschriften, div-Containern oder p-Tags befanden.


# Was steht als nächstes an?
Als nächstes sollte eine Investionen in den Premium-Plan von Alpha Vantage in Betracht gezogen werden. Mit diesem hätte man dann die Möglichkeit, bis zu 1200 Anfragen pro Minute zu stellen, was für die meisten Anwendungsfälle mehr als ausreichend wäre. Der Web Scraper sollte um rotierende Proxies o.Ä. erweitert werden, damit Artikel zu jeder Branche ausgegeben und gespeichert werden können. Des Weiteren sollten dann in einem nächsten Schritt die Daten aufbereitet und ausgewertet werden, um künftig statistische Analysen darauf anwenden zu können.